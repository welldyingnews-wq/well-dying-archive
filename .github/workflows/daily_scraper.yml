name: Well-Dying News Scraper

on:
  push: # ⭐ 파일을 저장(Commit)하는 순간 즉시 실행됩니다! (테스트용)
  schedule:
    # 30분마다
    - cron: '*/30 * * * *'
  workflow_dispatch: # 깃허브 웹에서 버튼으로 실행 가능

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    - name: 1. 코드 내려받기
      uses: actions/checkout@v3

    - name: 2. 파이썬 설치
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: 3. 라이브러리 설치
      # 낡은 라이브러리(pygooglenews)를 버렸으므로, 이제 복잡한 옵션 없이 깔끔하게 설치됩니다.
      run: pip install -r requirements.txt

    - name: 4. 비밀 열쇠 파일 생성
      # 깃허브 Secrets에 저장해둔 내용을 꺼내서 파일로 만듭니다.
      run: |
        echo '${{ secrets.GOOGLE_JSON_CONTENT }}' > service_account.json

    - name: 5. 수집기 실행
      env:
        # 필요한 환경변수 주입
        GENAI_API_KEY: ${{ secrets.GENAI_API_KEY }}
        NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
        NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}
        NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        GOOGLE_SHEET_JSON_PATH: service_account.json
      run: python collector.py
