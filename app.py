import streamlit as st
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import os
import json

# â­ Supabase ì°½ê³ ì§€ê¸° ë¶ˆëŸ¬ì˜¤ê¸° (í•„ìˆ˜!)
import database 

# ---------------------------
# 1. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° (ì„¤ì • ê´€ë¦¬ìš©)
# ---------------------------
@st.cache_resource
def get_client():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    json_path = "service_account.json"
    
    # ìŠ¤íŠ¸ë¦¼ë¦¿ Secretsì—ì„œ êµ¬ê¸€ í‚¤ ê°€ì ¸ì˜¤ê¸°
    if "private_key" in st.secrets:
        service_account_info = {
            "type": "service_account",
            "project_id": st.secrets["project_id"],
            "private_key_id": st.secrets["private_key_id"],
            "private_key": st.secrets["private_key"],
            "client_email": st.secrets["client_email"],
            "client_id": st.secrets["client_id"],
            "auth_uri": "https://accounts.google.com/o/oauth2/auth",
            "token_uri": "https://oauth2.googleapis.com/token",
            "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
            "client_x509_cert_url": st.secrets["client_x509_cert_url"]
        }
        with open(json_path, "w") as f: json.dump(service_account_info, f)
        
    creds = ServiceAccountCredentials.from_json_keyfile_name(json_path, scope)
    return gspread.authorize(creds)

def get_data(sheet_name):
    client = get_client()
    return client.open("Global Well-Dying Archive").worksheet(sheet_name)

# ---------------------------
# 2. ë©”ì¸ UI
# ---------------------------
st.set_page_config(page_title="Global Well-Dying Archive", layout="wide")
st.title("ğŸŒ Global Well-Dying News Archive")

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • ê´€ë¦¬ (êµ¬ê¸€ ì‹œíŠ¸)")
    
    # --- ìˆ˜ì§‘ ì£¼ê¸° ì„¤ì • ---
    with st.expander("â±ï¸ ìˆ˜ì§‘ ì£¼ê¸° ì„¤ì •"):
        try:
            sh_settings = get_data("Settings")
            current_interval = sh_settings.cell(2, 2).value
            st.info(f"í˜„ì¬ ì„¤ì •: {current_interval}ë¶„ ë§ˆë‹¤")
            
            new_interval = st.selectbox("ì£¼ê¸° ë³€ê²½", options=["30", "60", "120", "180", "360", "720"], index=1)
            
            if st.button("ì£¼ê¸° ì ìš©"):
                sh_settings.update_cell(2, 2, new_interval)
                st.success(f"{new_interval}ë¶„ìœ¼ë¡œ ë³€ê²½ ì™„ë£Œ!")
                st.cache_data.clear()
        except:
            st.error("'Settings' ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # --- í‚¤ì›Œë“œ ê´€ë¦¬ ---
    with st.expander("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ ê´€ë¦¬"):
        new_keyword = st.text_input("ìƒˆ í‚¤ì›Œë“œ ì¶”ê°€")
        if st.button("í‚¤ì›Œë“œ ì €ì¥"):
            if new_keyword:
                get_data("Keywords").append_row([new_keyword])
                st.success("ì¶”ê°€ ì™„ë£Œ!")
                
    # --- ê¸ˆì§€ì–´ ê´€ë¦¬ ---
    with st.expander("ğŸš« ê¸ˆì§€ì–´ ê´€ë¦¬"):
        new_ban_word = st.text_input("ìƒˆ ê¸ˆì§€ì–´ ì¶”ê°€")
        if st.button("ê¸ˆì§€ì–´ ì €ì¥"):
            if new_ban_word:
                get_data("BanWords").append_row([new_ban_word])
                st.success("ì¶”ê°€ ì™„ë£Œ!")

    # --- ì‚¬ì´íŠ¸ ê´€ë¦¬ ---
    with st.expander("ğŸ“¡ ëª¨ë‹ˆí„°ë§ ì‚¬ì´íŠ¸"):
        new_site_name = st.text_input("ì‚¬ì´íŠ¸ ì´ë¦„")
        new_site_url = st.text_input("RSS URL")
        if st.button("ì‚¬ì´íŠ¸ ì €ì¥"):
            if new_site_name and new_site_url:
                get_data("Sites").append_row([new_site_name, new_site_url])
                st.success("ì¶”ê°€ ì™„ë£Œ!")

    st.divider()
    
    # AI ë¶„ì„ ë²„íŠ¼ (ì›í•  ë•Œ ëˆ„ë¥´ê¸°)
    if st.button("ğŸ¤– AI ë‰´ìŠ¤ ë¶„ì„ (ìµœì‹  5ê°œ)"):
        import ai_analyst
        with st.spinner("ì œë¯¸ë‚˜ì´ê°€ ê¸°ì‚¬ë¥¼ ì½ëŠ” ì¤‘..."):
            ai_analyst.analyze_news()
        st.success("ë¶„ì„ ì™„ë£Œ! ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.")

    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()

# --- ë©”ì¸ í™”ë©´ (ì—¬ê¸°ê°€ ì™„ì „íˆ ë°”ë€Œì—ˆìŠµë‹ˆë‹¤!) ---
try:
    # 1. Supabaseì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    raw_data = database.load_news()
    df = pd.DataFrame(raw_data)

    if not df.empty:
        # 2. ë³´ê¸° ì¢‹ê²Œ ì»¬ëŸ¼ ì´ë¦„ í•œê¸€ë¡œ ë³€ê²½
        # (Supabase ì˜ì–´ ì»¬ëŸ¼ -> ëŒ€ì‹œë³´ë“œ í•œê¸€ ì»¬ëŸ¼)
        df = df.rename(columns={
            "collected_at": "ìˆ˜ì§‘ì¼ì‹œ",
            "source": "ì¶œì²˜",
            "title": "ì œëª©",
            "link": "ë§í¬",
            "ai_summary": "AIìš”ì•½",
            "ai_tags": "íƒœê·¸"
        })

        # 3. í•„í„° UI
        col1, col2 = st.columns(2)
        search = col1.text_input("ì œëª© ê²€ìƒ‰", placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        source = col2.multiselect("ì¶œì²˜ í•„í„°", df['ì¶œì²˜'].unique())
        
        if search: df = df[df['ì œëª©'].str.contains(search, case=False)]
        if source: df = df[df['ì¶œì²˜'].isin(source)]

        st.markdown(f"### ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ({len(df)}ê±´)")
        
        # 4. ë°ì´í„° í‘œì‹œ (AI ìš”ì•½ í¬í•¨)
        st.dataframe(
            df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "ë§í¬": st.column_config.LinkColumn("ì›ë¬¸ ë³´ê¸°"),
                "AIìš”ì•½": st.column_config.TextColumn("AI 3ì¤„ ìš”ì•½", width="medium"),
                "íƒœê·¸": st.column_config.TextColumn("íƒœê·¸", width="small")
            },
            # ë³´ì—¬ì¤„ ì»¬ëŸ¼ ìˆœì„œ ì§€ì •
            column_order=["ìˆ˜ì§‘ì¼ì‹œ", "ì¶œì²˜", "ì œëª©", "AIìš”ì•½", "íƒœê·¸", "ë§í¬"]
        )
    else:
        st.info("ì•„ì§ Supabaseì— ì €ì¥ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ì§‘ê¸°ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”!")

except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
