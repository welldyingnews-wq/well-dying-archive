import streamlit as st
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import os
import json

# ---------------------------
# 1. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
# ---------------------------
@st.cache_resource
def get_client():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    json_path = "service_account.json"

    if "private_key" in st.secrets:
        service_account_info = {
            "type": "service_account",
            "project_id": st.secrets["project_id"],
            "private_key_id": st.secrets["private_key_id"],
            "private_key": st.secrets["private_key"],
            "client_email": st.secrets["client_email"],
            "client_id": st.secrets["client_id"],
            "auth_uri": "https://accounts.google.com/o/oauth2/auth",
            "token_uri": "https://oauth2.googleapis.com/token",
            "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
            "client_x509_cert_url": st.secrets["client_x509_cert_url"]
        }
        with open(json_path, "w") as f:
            json.dump(service_account_info, f)

    creds = ServiceAccountCredentials.from_json_keyfile_name(json_path, scope)
    return gspread.authorize(creds)

def get_data(sheet_name):
    client = get_client()
    sh = client.open("Global Well-Dying Archive")
    return sh.worksheet(sheet_name)

# ---------------------------
# 2. ë©”ì¸ UI
# ---------------------------
st.set_page_config(page_title="Global Well-Dying Archive", layout="wide")
st.title("ğŸŒ Global Well-Dying News Archive")

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • ê´€ë¦¬")
    
    # --- 1. ê²€ìƒ‰ í‚¤ì›Œë“œ ---
    with st.expander("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ ê´€ë¦¬"):
        new_keyword = st.text_input("ìƒˆ í‚¤ì›Œë“œ ì¶”ê°€")
        if st.button("í‚¤ì›Œë“œ ì €ì¥"):
            if new_keyword:
                sh = get_data("Keywords")
                sh.append_row([new_keyword])
                st.success(f"'{new_keyword}' ì¶”ê°€ ì™„ë£Œ!")
                st.cache_data.clear()

    # --- 2. ê¸ˆì§€ì–´ ---
    with st.expander("ğŸš« ê¸ˆì§€ì–´(í•„í„°) ê´€ë¦¬"):
        new_ban_word = st.text_input("ìƒˆ ê¸ˆì§€ì–´ ì¶”ê°€")
        if st.button("ê¸ˆì§€ì–´ ì €ì¥"):
            if new_ban_word:
                try:
                    sh = get_data("BanWords")
                    sh.append_row([new_ban_word])
                    st.success(f"'{new_ban_word}' ì°¨ë‹¨ ì™„ë£Œ!")
                    st.cache_data.clear()
                except:
                    st.error("'BanWords' ì‹œíŠ¸ë¥¼ ë¨¼ì € ë§Œë“¤ì–´ì£¼ì„¸ìš”!")

    # --- 3. [NEW] ëª¨ë‹ˆí„°ë§ ì‚¬ì´íŠ¸ ---
    with st.expander("ğŸ“¡ ëª¨ë‹ˆí„°ë§ ì‚¬ì´íŠ¸(RSS)"):
        st.caption("ë‰´ìŠ¤ ì‚¬ì´íŠ¸ì˜ RSS ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        new_site_name = st.text_input("ì‚¬ì´íŠ¸ ì´ë¦„ (ì˜ˆ: CNN)")
        new_site_url = st.text_input("RSS ì£¼ì†Œ (URL)")
        
        if st.button("ì‚¬ì´íŠ¸ ì €ì¥"):
            if new_site_name and new_site_url:
                try:
                    sh = get_data("Sites")
                    sh.append_row([new_site_name, new_site_url])
                    st.success(f"'{new_site_name}' ì¶”ê°€ ì™„ë£Œ!")
                    st.cache_data.clear()
                except:
                    st.error("'Sites' ì‹œíŠ¸(íƒ­)ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!")
        
        # ë“±ë¡ëœ ì‚¬ì´íŠ¸ ëª©ë¡ ë³´ê¸°
        try:
            sh = get_data("Sites")
            sites_data = sh.get_all_records()
            if sites_data:
                st.caption(f"í˜„ì¬ {len(sites_data)}ê°œ ê°ì‹œ ì¤‘")
                st.dataframe(pd.DataFrame(sites_data), hide_index=True)
        except:
            st.warning("'Sites' íƒ­ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()
    if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()

# --- ë©”ì¸ ë‰´ìŠ¤ í™”ë©´ ---
try:
    sh = get_data("News")
    rows = sh.get_all_records()
    df = pd.DataFrame(rows)

    if not df.empty:
        col1, col2 = st.columns(2)
        with col1:
            search_query = st.text_input("ì œëª© ê²€ìƒ‰", placeholder="ê´€ì‹¬ìˆëŠ” ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        with col2:
            source_filter = st.multiselect("ì¶œì²˜ í•„í„°", df['ì¶œì²˜'].unique())

        if search_query:
            df = df[df['ì œëª©'].str.contains(search_query, case=False)]
        if source_filter:
            df = df[df['ì¶œì²˜'].isin(source_filter)]

        st.markdown(f"### ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ({len(df)}ê±´)")
        st.dataframe(
            df[['ìˆ˜ì§‘ì¼ì‹œ', 'ì¶œì²˜', 'ì œëª©', 'ìš”ì•½', 'ë§í¬']],
            use_container_width=True,
            hide_index=True,
            column_config={
                "ë§í¬": st.column_config.LinkColumn("ê¸°ì‚¬ ë³´ê¸°")
            }
        )
    else:
        st.info("ì•„ì§ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
except Exception as e:
    st.error(f"ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
