import os
import json
import requests
import time
import pandas as pd
from datetime import datetime
from typing import List, Dict

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import google.generativeai as genai
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from pygooglenews import GoogleNews
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ (ë³´ì•ˆ)
load_dotenv()

# ==========================================
# 1. í™˜ê²½ ì„¤ì • ë° ìƒìˆ˜ (Configuration)
# ==========================================
GENAI_API_KEY = os.getenv("GENAI_API_KEY")
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")
NEWS_API_KEY = os.getenv("NEWS_API_KEY")
SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")
GOOGLE_SHEET_KEY = os.getenv("GOOGLE_SHEET_JSON_PATH") # json íŒŒì¼ ê²½ë¡œ

# AI ëª¨ë¸ ì„¤ì •
genai.configure(api_key=GENAI_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

# ==========================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (Slack, Sheet)
# ==========================================

def send_slack_alert(news_item: Dict, analysis: Dict):
    """ì¤‘ìš” ë‰´ìŠ¤ ìŠ¬ë™ ì•Œë¦¼ ì „ì†¡"""
    emoji = "ğŸŒŸ" if analysis['sentiment'] == "í¬ë§(ê¸ì •)" else "ğŸ“¢"
    color = "#36a64f" if analysis['sentiment'] == "í¬ë§(ê¸ì •)" else "#ff0000"
    
    payload = {
        "text": f"{emoji} [ì¤‘ìš”] ì›°ë‹¤ì‰ ë‰´ìŠ¤ ì•Œë¦¼: {news_item['title']}",
        "blocks": [
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*{emoji} {news_item['title']}*\n\n*ì¶œì²˜:* {news_item['source_type']} | *ê°ì •:* {analysis['sentiment']}\n{analysis['summary']}"
                }
            },
            {
                "type": "context",
                "elements": [{"type": "mrkdwn", "text": f"<{news_item['link']}|ê¸°ì‚¬ ì›ë¬¸ ë³´ê¸°>"}]
            }
        ]
    }
    try:
        requests.post(SLACK_WEBHOOK_URL, json=payload)
    except Exception as e:
        print(f"Slack ì „ì†¡ ì‹¤íŒ¨: {e}")

def get_existing_links(sheet) -> List[str]:
    """ì‹œíŠ¸ì—ì„œ ì´ë¯¸ ì €ì¥ëœ ê¸°ì‚¬ ë§í¬ ëª©ë¡ì„ ê°€ì ¸ì˜´ (ì¤‘ë³µ ë°©ì§€ìš©)"""
    try:
        return sheet.col_values(8) # 8ë²ˆì§¸ ì—´ì´ 'ì›ë¬¸ë§í¬'ë¼ê³  ê°€ì •
    except:
        return []

# ==========================================
# 3. ë°ì´í„° ìˆ˜ì§‘ê¸° (Collectors)
# ==========================================

def fetch_naver_news(keywords: List[str]) -> List[Dict]:
    """[êµ­ë‚´] ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    results = []
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    
    for kw in keywords:
        url = f"https://openapi.naver.com/v1/search/news.json?query={kw}&display=5&sort=sim"
        try:
            res = requests.get(url, headers=headers)
            items = res.json().get('items', [])
            for item in items:
                results.append({
                    'title': item['title'].replace('<b>', '').replace('</b>', ''), # íƒœê·¸ ì œê±°
                    'link': item['link'],
                    'content': item['description'],
                    'source_type': 'NAVER(êµ­ë‚´)'
                })
        except Exception as e:
            print(f"ë„¤ì´ë²„ ìˆ˜ì§‘ ì—ëŸ¬ ({kw}): {e}")
            
    return results

def fetch_pygooglenews(keywords: List[str]) -> List[Dict]:
    """[í•´ì™¸] Google News RSS ê²€ìƒ‰ (ê´‘ë²”ìœ„ ìˆ˜ì§‘)"""
    gn = GoogleNews(lang='en', country='US') # ê¸°ë³¸ ì„¤ì •
    results = []
    
    for kw in keywords:
        try:
            search = gn.search(kw)
            for entry in search['entries'][:5]:
                results.append({
                    'title': entry.title,
                    'link': entry.link,
                    'content': entry.title, # RSSëŠ” ë³¸ë¬¸ì´ ì—†ìœ¼ë¯€ë¡œ ì œëª©ìœ¼ë¡œ ëŒ€ì²´
                    'source_type': 'GOOGLE_RSS(í•´ì™¸)'
                })
        except Exception as e:
            print(f"Google News ìˆ˜ì§‘ ì—ëŸ¬ ({kw}): {e}")
    return results

def fetch_newsapi(keywords: List[str]) -> List[Dict]:
    """[í•´ì™¸] NewsAPI.org (ë©”ì´ì € ì–¸ë¡ ì‚¬ íƒ€ê²Ÿ)"""
    results = []
    for kw in keywords:
        url = f"https://newsapi.org/v2/everything?q={kw}&sortBy=publishedAt&apiKey={NEWS_API_KEY}&language=en"
        try:
            res = requests.get(url)
            articles = res.json().get('articles', [])
            for item in articles[:5]:
                results.append({
                    'title': item['title'],
                    'link': item['url'],
                    'content': item['description'] or item['title'],
                    'source_type': 'NEWS_API(ì™¸ì‹ )'
                })
        except Exception as e:
             print(f"NewsAPI ìˆ˜ì§‘ ì—ëŸ¬ ({kw}): {e}")
    return results

# ==========================================
# 4. AI ë‘ë‡Œ (Gemini Processor)
# ==========================================

def analyze_with_gemini(news_item: Dict) -> Dict:
    """
    Geminiì—ê²Œ ê¸°ì‚¬ ë¶„ì„, ë²ˆì—­, ìš”ì•½, ë¶„ë¥˜ë¥¼ ìš”ì²­
    """
    prompt = f"""
    ë‹¹ì‹ ì€ 'ì›°ë‹¤ì‰(Well-Dying)' ì „ë¬¸ ë‰´ìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
    ì•„ë˜ ê¸°ì‚¬ëŠ” ì˜ì–´ì¼ ìˆ˜ë„ ìˆê³  í•œêµ­ì–´ì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
    
    [ê¸°ì‚¬ ì •ë³´]
    ì œëª©: {news_item['title']}
    ë‚´ìš©: {news_item['content']}
    ì¶œì²˜: {news_item['source_type']}

    [ì§€ì‹œì‚¬í•­]
    1. **ê´€ë ¨ì„± íŒë‹¨**: ì´ ê¸°ì‚¬ê°€ 'ì£½ìŒ, í˜¸ìŠ¤í”¼ìŠ¤, ì¥ë¡€, ì¡´ì—„ì‚¬, ì—°ëª…ì˜ë£Œ'ì™€ ë°€ì ‘í•œ ê´€ë ¨ì´ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”. (ê´‘ê³ ë‚˜ ë‹¨ìˆœ ë¶€ê³ ëŠ” ì œì™¸)
    2. **ë²ˆì—­ ë° ìš”ì•½**: ê¸°ì‚¬ê°€ ì™¸êµ­ì–´ë¼ë©´ **ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­**í•˜ì—¬ í•µì‹¬ ë‚´ìš©ì„ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
    3. **ê°ì • ë¶„ì„**: ê¸°ì‚¬ì˜ í†¤ì„ [í¬ë§(ê¸ì •), ë…¼ìŸ(ì¤‘ë¦½), ë¹„ë³´(ë¶€ì •)] ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
    4. **ì¹´í…Œê³ ë¦¬**: [ì •ì±…/ë²•ì•ˆ, ê¸°ìˆ /ì˜í•™, ë¬¸í™”/ì—ì„¸ì´, ì‚¬ê±´/ì‚¬ê³ ] ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
    5. **ì¤‘ìš”ë„**: 1~5ì  (5ì ì´ ê°€ì¥ ì¤‘ìš”). ì›°ë‹¤ì‰ íŠ¸ë Œë“œë‚˜ ë²•ì•ˆ ë³€ê²½ ë“±ì€ ë†’ì€ ì ìˆ˜.

    [ì‘ë‹µ í˜•ì‹ - JSONë§Œ ì¶œë ¥]
    {{
        "is_relevant": true/false,
        "summary": "í•œêµ­ì–´ ìš”ì•½ ë‚´ìš©...",
        "sentiment": "ê°ì •ë¶„ì„ ê²°ê³¼",
        "category": "ì¹´í…Œê³ ë¦¬",
        "priority": 3
    }}
    """
    
    try:
        response = model.generate_content(prompt)
        text = response.text.replace('```json', '').replace('```', '').strip()
        return json.loads(text)
    except Exception as e:
        print(f"AI ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

# ==========================================
# 5. ë©”ì¸ ì‹¤í–‰ ì»¨íŠ¸ë¡¤ëŸ¬ (Main)
# ==========================================

def main():
    print("ğŸš€ ì›°ë‹¤ì‰ ë‰´ìŠ¤ ì•„ì¹´ì´ë¹™ ì‹œìŠ¤í…œ ê°€ë™...")
    
    # 1. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_name(GOOGLE_SHEET_KEY, scope)
    client = gspread.authorize(creds)
    sheet = client.open("Global Well-Dying Archive").sheet1 # ì‹œíŠ¸ ì´ë¦„ í™•ì¸!
    
    existing_links = get_existing_links(sheet)
    print(f"ğŸ“Š ê¸°ì¡´ ë°ì´í„° {len(existing_links)}ê°œ ë¡œë“œ ì™„ë£Œ.")

    # 2. ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘
    all_news = []
    
    # (A) êµ­ë‚´
    print("ğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ íƒìƒ‰ ì¤‘...")
    all_news.extend(fetch_naver_news(["ì›°ë‹¤ì‰", "í˜¸ìŠ¤í”¼ìŠ¤", "ì¡´ì—„ì‚¬", "ì—°ëª…ì˜ë£Œ"]))
    
    # (B) í•´ì™¸ (Google RSS)
    print("ğŸ” êµ¬ê¸€ ê¸€ë¡œë²Œ ë‰´ìŠ¤ íƒìƒ‰ ì¤‘...")
    all_news.extend(fetch_pygooglenews(["Euthanasia law", "Hospice care trends"]))
    
    # (C) í•´ì™¸ (NewsAPI)
    print("ğŸ” NewsAPI ì™¸ì‹  íƒìƒ‰ ì¤‘...")
    all_news.extend(fetch_newsapi(["End of life care", "Assisted dying"]))

    print(f"ì´ {len(all_news)}ê°œì˜ í›„ë³´ ê¸°ì‚¬ ìˆ˜ì§‘ë¨. AI ë¶„ì„ ì‹œì‘...")

    # 3. AI ë¶„ì„ ë° í•„í„°ë§
    new_rows = []
    
    for news in all_news:
        #
        # === [ì†ë„ ì¡°ì ˆ ì½”ë“œ ì‹œì‘] ===
        print(f"â³ ê³¼ì† ë°©ì§€: 15ì´ˆ ëŒ€ê¸° ì¤‘... (í˜„ì¬ ê¸°ì‚¬: {news['title'][:10]}...)")
        time.sleep(15) 
        # ===========================
    
        # ì¤‘ë³µ ê²€ì‚¬ (ë§í¬ ê¸°ì¤€)
        if news['link'] in existing_links:
            continue
            
        # AI ë¶„ì„
        analysis = analyze_with_gemini(news)
        
        if analysis and analysis['is_relevant']:
            # ë°ì´í„° í–‰ ìƒì„±
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
            row = [
                timestamp,
                news['source_type'],      # ì¶œì²˜ ë¶„ë¥˜ (NAVER, GOOGLE_RSS, NEWS_API)
                analysis['category'],
                news['title'],
                analysis['summary'],      # í•œêµ­ì–´ë¡œ ë²ˆì—­ëœ ìš”ì•½
                analysis['sentiment'],
                analysis['priority'],
                news['link']
            ]
            new_rows.append(row)
            print(f"âœ… ì €ì¥ë¨: {news['title']}")
            
            # ì¤‘ìš” ë‰´ìŠ¤ ìŠ¬ë™ ì•Œë¦¼ (ì¤‘ìš”ë„ 4 ì´ìƒ)
            if analysis['priority'] >= 4:
                send_slack_alert(news, analysis)
        else:
            print(f"âŒ ìŠ¤í‚µë¨(ê´€ë ¨ì—†ìŒ): {news['title']}")

    # 4. ì‹œíŠ¸ì— ì¼ê´„ ì €ì¥ (API í˜¸ì¶œ ìµœì†Œí™”)
    if new_rows:
        sheet.append_rows(new_rows)
        print(f"ğŸ’¾ ì´ {len(new_rows)}ê°œì˜ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("â˜ï¸ ì €ì¥í•  ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()